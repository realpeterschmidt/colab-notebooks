{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c630c5",
   "metadata": {},
   "source": [
    "Before running, install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy sklearn torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bea5b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30875454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from torchvision import datasets, transforms\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85c502",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# COMMENT THIS OUT IF YOU USE YOUR OWN DATA.\n",
    "# Download example data into ./data/image-data (4 image files, 2 for \"dog\", 2 for \"cat\").\n",
    "url = \"https://github.com/jrieke/traingenerator/raw/main/data/fake-image-data.zip\"\n",
    "zip_path, _ = urllib.request.urlretrieve(url)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "    f.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ac822",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301a70a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# INSERT YOUR DATA HERE\n",
    "# Expected format: One folder per class, e.g.\n",
    "# train\n",
    "# --- dogs\n",
    "# |   +-- lassie.jpg\n",
    "# |   +-- komissar-rex.png\n",
    "# --- cats\n",
    "# |   +-- garfield.png\n",
    "# |   +-- smelly-cat.png\n",
    "#\n",
    "# Example: https://github.com/jrieke/traingenerator/tree/main/data/image-data\n",
    "train_data = \"data/image-data\"  # required\n",
    "val_data = \"data/image-data\"    # optional\n",
    "test_data = None                # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789aa16e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2aa8d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up scaler.\n",
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d875aa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return None\n",
    "    # Read image files to pytorch dataset (only temporary).\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(28), \n",
    "        transforms.CenterCrop(28), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    data = datasets.ImageFolder(data, transform=transform)\n",
    "\n",
    "    # Convert to numpy arrays.\n",
    "    images_shape = (len(data), *data[0][0].shape)\n",
    "    images = np.zeros(images_shape)\n",
    "    labels = np.zeros(len(data))\n",
    "    for i, (image, label) in enumerate(data):\n",
    "        images[i] = image\n",
    "        labels[i] = label\n",
    "    \n",
    "    # Flatten.\n",
    "    images = images.reshape(len(images), -1)\n",
    "\n",
    "    # Scale to mean 0 and std 1.\n",
    "    if name == \"train\":\n",
    "        scaler.fit(images)\n",
    "    images = scaler.transform(images)\n",
    "\n",
    "    # Shuffle train set.\n",
    "    if name == \"train\":\n",
    "        images, labels = sklearn.utils.shuffle(images, labels)\n",
    "\n",
    "    return [images, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39228bac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "processed_train_data = preprocess(train_data, \"train\")\n",
    "processed_val_data = preprocess(val_data, \"val\")\n",
    "processed_test_data = preprocess(test_data, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4b7f0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61600fac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc59332",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2936dd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return\n",
    "\n",
    "    images, labels = data\n",
    "    acc = model.score(images, labels)\n",
    "    print(f\"{name + ':':6} accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on train_data.\n",
    "model.fit(*processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c90692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on all datasets.\n",
    "evaluate(processed_train_data, \"train\")\n",
    "evaluate(processed_val_data, \"val\")\n",
    "evaluate(processed_test_data, \"test\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}